{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv,os,sys\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#content = requests.get(url)\n",
    "#page = BeautifulSoup(open('Coronavirus (COVID19) _ JAMA Network.html'), \"html.parser\")\n",
    "\n",
    "lancetpage = \"https://www.thelancet.com/coronavirus\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\",\n",
    "    \"Accept-Encoding\": \"*\",\n",
    "    \"Connection\": \"keep-alive\"\n",
    "}\n",
    "htmlpage = requests.get(lancetpage, headers=headers)\n",
    "\n",
    "page = BeautifulSoup(htmlpage.text, \"html.parser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for entry in mydiv.find_all(\"h4\", attrs={\"class\": \"title\"}):\n",
    "    txt.append(entry.text)\n",
    "    \n",
    "for entry in mydiv.find_all(\"div\", attrs={\"class\": \"articleType\"}):\n",
    "    Type.append(entry.text)\n",
    "    \n",
    "for entry in mydiv.find_all(\"div\", attrs={\"class\": \"published-online\"}):\n",
    "    Pdate = entry.text.split('Published: ')[-1]\n",
    "    Pdate = datetime.strptime(Pdate , '%b %d %Y')\n",
    "    Dates.append(Pdate.strftime(\"%Y%m%d\"))\n",
    "    \n",
    "for entry in mydiv.find_all(\"div\", attrs={\"class\": \"doi\"}):\n",
    "    \n",
    "    ID.append(entry.text.split('/')[-1])\n",
    "    link.append(entry.text)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FormatAbstract (AB):\n",
    "\n",
    "    Abstract = ''\n",
    "    tempAbs = AB.split(' ')\n",
    "    lastN=0\n",
    "    newabs = []\n",
    "    for N in range(30, len(tempAbs)+30, 30) :\n",
    "        newabs.append(' '.join(tempAbs[lastN:N]))\n",
    "        lastN= N\n",
    "\n",
    "    Abstract = '\\n'.join(newabs)\n",
    "\n",
    "    return(Abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = []\n",
    "link = []\n",
    "ID = []\n",
    "AB = []\n",
    "Dates = []\n",
    "Type = []\n",
    "\n",
    "mydiv = page.select('div.widget-body.body.body-regular')[0]\n",
    "\n",
    "for entry in mydiv.find_all(\"h4\", attrs={\"class\": \"title\"}):\n",
    "    txt.append(entry.text)\n",
    "    \n",
    "for entry in mydiv.find_all(\"div\", attrs={\"class\": \"articleType\"}):\n",
    "    Type.append(entry.text)\n",
    "    \n",
    "for entry in mydiv.find_all(\"div\", attrs={\"class\": \"published-online\"}):\n",
    "    Pdate = entry.text.split('Published: ')[-1]\n",
    "    Pdate = datetime.strptime(Pdate , '%B %d, %Y')\n",
    "    Dates.append(Pdate.strftime(\"%Y%m%d\"))\n",
    "    \n",
    "for entry in mydiv.find_all(\"div\", attrs={\"class\": \"doi\"}):\n",
    "    \n",
    "    ID.append(entry.text.split('/')[-1])\n",
    "    link.append(entry.text)\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'lancent.json'\n",
    "dict_file = 'lancent_dict_file.json'\n",
    "\n",
    "\n",
    "#read the stored dictionary file (dict_file) or create a new blank dictionary\n",
    "if os.path.isfile(dict_file):\n",
    "    jsondict = json.load(open(dict_file))\n",
    "else:\n",
    "    jsondict = {}    \n",
    "    \n",
    "    \n",
    "for N in range(0, len(ID)) :\n",
    "    if ID[N] not in jsondict.keys():\n",
    "        jsondict[ID[N]] = {'ID' : ID[N] , \n",
    "                          'txt' : txt[N],\n",
    "                          'link' : link[N],\n",
    "                           'Dates' : Dates[N],\n",
    "                           'Type' : Type[N]\n",
    "                          }\n",
    "jsondict\n",
    "\n",
    "\n",
    "#Write the main json file\n",
    "with open(json_file , 'w') as fp:   \n",
    "    Output=[]\n",
    "    for Key,Item in jsondict.items():\n",
    "        Output.append(Item)\n",
    "    json.dump(Output, fp)\n",
    "\n",
    "#Write the exact dict as json file (easily read by the script)\n",
    "with open(dict_file , 'w') as fp:   \n",
    "    json.dump(jsondict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeTemplate():\n",
    "    headerslist = []\n",
    "    for H in ('ID' ,'txt'  ,'link' ,'Dates' ,'Type' ):\n",
    "\n",
    "        print(H)\n",
    "        headers = '=ImportJSON(\"https://raw.githubusercontent.com/tofaquih/coronaPubGet/master/lancent.json\", \"/{}\", \"noInherit,noTruncate\")'.format(H)\n",
    "        headerslist.append(headers)\n",
    "\n",
    "    headerslist\n",
    "    with open('lancent_template.csv' ,'w'  , newline='' ) as fp:\n",
    "        W = csv.writer(fp, delimiter=';')\n",
    "        W.writerow(headerslist)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "txt\n",
      "link\n",
      "Dates\n",
      "Type\n"
     ]
    }
   ],
   "source": [
    "MakeTemplate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
